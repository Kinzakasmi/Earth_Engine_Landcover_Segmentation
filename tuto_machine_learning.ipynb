{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Pipeline\n",
    "<img src=\"tuto_images/9.PNG?modified=02022021200000\" width=\"800\">  \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red> Welcome to this machine learninig prediction tutorial ! </font>\n",
    "            \n",
    "### There are 4 different steps :   \n",
    ">- Install and import libraries, create folders and define parameters.  \n",
    ">    *Parameters followed by **#@param** are variables, you can change them.*\n",
    ">- Construct your dataset. \n",
    ">- Load and process your dataset.\n",
    ">- Train and evaluate your model.  \n",
    ">- Predict your zone of interest. \n",
    "\n",
    "**If you already have a pretrained model, do only step 1 and 4**\n",
    "\n",
    "### Table of Contents\n",
    "* [I. Libraries and Variables](#I.-Libraries-and-Variables)\n",
    "* [II. Training](#II.-Training) (**skip this if you already have a pretrained model**)\n",
    "    - [II. 1. Dataset Construction](#II.-1.-Dataset-Construction)\n",
    "    - [II. 2. Dataset Loading and Processing](#II.-2.-Dataset-Loading-and-Processing)\n",
    "    - [II. 3. Model Training and Evaluation](#II.-3.-Model-Training-and-Evaluation)\n",
    "* [III. Inference](#III.-Inference)  \n",
    "    - [III. 1. Label Image](#III.-1.-Label-Image)\n",
    "    - [III. 2. Pipe Classification, Network Statistics and KMLs](#III.-2.-Pipe-Classification,-Network-Statistics-and-KMLs)\n",
    "* [IV. Google Earth Engine Editor Tutorials](#IV.-Tutorials)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Libraries and Variables\n",
    "### First create a new virtual environment (you will have problems with your package versions otherwise)  \n",
    "### Then install all requirements by running the following :\n",
    "\n",
    "*Careful* if you have multiple python versions :\n",
    "- If you are on your default python, run : **!pip** install -r requirements.txt\n",
    "- If you are on another python version, add your version number to pip. Example, if you are working on python3.8 run **!pip3.8** install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which python you use for your default pipe\n",
    "!pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the version of pip if needed\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_folders\n",
    "import tensorflow as tf\n",
    "from dataset_construction import TFDatasetConstruction\n",
    "from dataset_loader import TFDatasetProcessing, NPDatasetProcessing, undersample\n",
    "from models import ModelTrainingAndEvaluation\n",
    "from joblib import load\n",
    "from inference import Inference, download_kml\n",
    "from utils import predict_pipes, predict_pipes_from_csv, clean_predictions, color_pipes, get_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import, authenticate and initialize the Earth Engine library.  \n",
    "If you have a gmail account and already have access to Earth Engine, do so with yours, if not, you can use this one. It was created for the purpose of this project:  \n",
    "Gmail adress : `mounierseb93@gmail.com`    \n",
    "Code : `mounse$15`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=g3Iu0S4lGxyu62uf9KMws1RZRFe8cyVF6Ln5UOcw5FQ&code_challenge_method=S256>https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=g3Iu0S4lGxyu62uf9KMws1RZRFe8cyVF6Ln5UOcw5FQ&code_challenge_method=S256</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you\n",
       "        should paste in the box below</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter verification code: 4/1AY0e-g6FWDy4T7lXoM1FL5cY8QZW1uslUEb4tcwoVTjQWhUHGf4WvfQKK4k\n",
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all folders you will need\n",
    "After running the following, your directory shoud be as following :\n",
    "Check if the folders are in your directory.\n",
    "- **Main folder**\n",
    "    * models\n",
    "    * results\n",
    "    * data\n",
    "        * train\n",
    "        * eval\n",
    "        * inference\n",
    "        * predictions\n",
    "            * colored_pipes\n",
    "            * kml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_folders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANDSAT  = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B10', 'B11']\n",
    "SENTINEL = ['VV','VH','VV_1','VH_1']\n",
    "BANDS    = LANDSAT + SENTINEL\n",
    "RESPONSE = 'landcover'\n",
    "FEATURES = BANDS+[RESPONSE]\n",
    "\n",
    "KERNEL_SIZE   = 128\n",
    "KERNEL_SHAPE  = [KERNEL_SIZE, KERNEL_SIZE]\n",
    "COLUMNS       = [tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES]\n",
    "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
    "NUM_FEATURES  = len(BANDS)\n",
    "NUM_CLASSES   = 4 \n",
    "\n",
    "LABEL_NAMES  = [0,1,2,3]\n",
    "TARGET_NAMES = ['field','forest','urban','water']\n",
    "\n",
    "#Do not change the following\n",
    "point  = None\n",
    "radius = None\n",
    "rectangle = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Training \n",
    "### <font color=red> If you already have a pretrained model <font>, skip this part and go to [III.inference](#III.-Inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------Specify preprocessing parameters-----------#\n",
    "\n",
    "TRAIN_SIZE = 5000 #@param {type:\"integer\"} #maximum : 5000\n",
    "EVAL_SIZE  = 3000 #@param {type:\"integer\"} #maximum : 3000\n",
    "\n",
    "# Whether to undersample (ie take the same number of pixels from each class)\n",
    "UNDERSAMPLING = True #@param {type:'boolean'}\n",
    "\n",
    "# The number of pixels taken from each class if undersampling=True, if None, set to the number of the rearest class\n",
    "SAMPLES_PER_CLASS = None #@param (None or integer)\n",
    "\n",
    "# Whether to add misclassified pixels from previous model \n",
    "# do not use this if you haven't learnt how to create them. Cf to my tutorial \"eeTutoriel.ipynb\"\n",
    "MISCLASSIFIED_PIXELS = False #@param {type:'boolean'}\n",
    "\n",
    "# The name of the Asset of misclassified pixels, if misclassified_pixels=True\n",
    "ASSETID = \"users/leakm/misclassified_pixels\"\n",
    "\n",
    "#-------------Specify model parameters--------------#\n",
    "\n",
    "# Careful, the name of your model should contain the model type such as : knn_something-something, or something-rf_something\n",
    "MODEL_NAME   = 'rf' #@param [\"knn\", \"svm\", \"rf\",\"pca_rf\",\"umap_rf\"] \n",
    "\n",
    "FINETUNE = False #@param {type: 'boolean'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. 1. Dataset Construction  \n",
    "If you don't have access to the training dataset (.tfrecord.gz in folders 'train' and 'eval'), download it from the Google Drive in this address and password (and make sur to add it the right folder with the same name as in the drive).   \n",
    "    Gmail adress : `mounierseb93@gmail.com`  \n",
    "    Code : `mounse$15`  \n",
    "      \n",
    "If it's not there for some reason, or if you want to construct your own, run the following :\n",
    "    \n",
    "*Every time your run a code, if you receive a message like this : \"Please download file from Drive from folder ...\", go to the Google Drive and to the folder mentioned, and download the file in the same folder on your computer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export training and evaluation tfrecords\n",
    "tfdataconstructor = TFDatasetConstruction(LANDSAT,SENTINEL,RESPONSE,KERNEL_SIZE)\n",
    "tfdataconstructor.dataset_construction(\"2017-01-01\",\"2017-12-31\") #the date should not change since the label dataset is from 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. 2. Dataset Loading and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process training and evaluation tf.Datasets\n",
    "tfdataloader = TFDatasetProcessing(FEATURES_DICT,FEATURES,BANDS,NUM_FEATURES,batch_size=BATCH_SIZE)\n",
    "training     = tfdataloader.get_training_dataset()\n",
    "evaluation   = tfdataloader.get_eval_dataset()\n",
    "NUM_FEATURES = tfdataloader.num_features\n",
    "\n",
    "# Convert tf.Datasets to numpy arrays\n",
    "npdataloader = NPDatasetProcessing(NUM_FEATURES,NUM_CLASSES)\n",
    "train        = npdataloader.tf_to_numpy(training,TRAIN_SIZE)\n",
    "eval         = npdataloader.tf_to_numpy(evaluation,EVAL_SIZE)\n",
    "del training,evaluation\n",
    "\n",
    "# Undersampling\n",
    "if UNDERSAMPLING :\n",
    "    train['features'],train['labels'] = undersample(train['features'],train['labels'],SAMPLES_PER_CLASS)\n",
    "    eval['features'] ,eval['labels']  = undersample(eval['features'],eval['labels'],SAMPLES_PER_CLASS)\n",
    "\n",
    "# Adding samples to the dataset\n",
    "if MISCLASSIFIED_PIXELS :\n",
    "    train = npdataloader.adding_more_pixels(train,ASSETID,tfdataconstructor,tfdataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. 3. Model Training and Evaluation\n",
    "You can :  \n",
    "## a. Train your model and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Model fitting, if you want to (re)train your model\n",
    "model = ModelTrainingAndEvaluation(MODEL_NAME,train,eval,FINETUNE)\n",
    "if 'pca' in MODEL_NAME :\n",
    "    model.pca(NUM_CLASSES)\n",
    "elif 'umap' in MODEL_NAME :\n",
    "    model.umap(NUM_CLASSES)\n",
    "elif 'knn' in MODEL_NAME :\n",
    "    model.knn() #check the parameters you can pass as arguments\n",
    "elif 'svm' in MODEL_NAME :\n",
    "    model.svm() #check the parameters you can pass as arguments\n",
    "elif 'rf' in MODEL_NAME :\n",
    "    model.rf() #check the parameters you can pass as arguments\n",
    "\n",
    "# Model evaluation\n",
    "%matplotlib inline\n",
    "model.eval_model(LABEL_NAMES,TARGET_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Evaluate a saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the name of the model (without the extension), it should be the same as the one in your folder \"models\"\n",
    "MODEL_NAME = 'rf' #@param "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelTrainingAndEvaluation(MODEL_NAME,train,eval,False)\n",
    "model.model = load('models/'+MODEL_NAME+'.joblib')\n",
    "model.eval_model(LABEL_NAMES,TARGET_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Inference\n",
    "\n",
    "This is how inference works, you specify the input location, the code will extract the test-image in that location and the pretrained model will process it and produce a mask image.\n",
    "    \n",
    "<img src=\"tuto_images/8.PNG?modified=08022021170000\" width=\"800\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the name of the model (without the extension), it should be the same as the one in your folder \"models\"\n",
    "MODEL_NAME = 'rf' #@param \n",
    "\n",
    "# Specify inference parameters\n",
    "\n",
    "# The image that will be created is the mean of an Image Collection of sattelite images. \n",
    "# You should specify the date range of this collection :\n",
    "start_date = \"2020-01-01\"   \n",
    "end_date   = \"2020-12-31\"\n",
    "\n",
    "image_name = 'test' #Name your image as you want\n",
    "\n",
    "#Whether to perform Conditional Random Fields on your predictions\n",
    "PERFORM_CRF = False #@param\n",
    "\n",
    "if PERFORM_CRF == True :\n",
    "    !pip install --upgrade cython\n",
    "    !pip install --upgrade pydensecrf\n",
    "    \n",
    "#If you are on windows and have trouble installing pydensecrf : \n",
    "#if you use anaconda, execute the following : conda install -c conda-forge pydensecrf').\n",
    "#if not, or you have more fails, check https://github.com/lucasb-eyer/pydensecrf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [1. Label Image](#III.-1.-Label-Image)  \n",
    "* [2. Pipe Classification, Network Statistics and KMLs](#III.-2.-Pipe-Classification,-Network-Statistics-and-KMLs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. 1. Label Image\n",
    "You have two options to how you create your test image :  \n",
    "* [1. Export an image from a square window of a given center `[Lon,Lat]` and `radius` (in meters)](#1.-Export-an-image-from-a-square-window-of-given-center-and-radius)\n",
    "* [2. Export an image from a window given a bounding box `[Lon1, Lat1, Lon2, Lat2]`](#2.-Export-an-image-from-a-window-given-a-bounding-box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill only one of the following :\n",
    "#### 1. Export an image from a square window of given center and radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon    = None #@param {type;'number'}\n",
    "lat    = None #@param {type:'number'}\n",
    "point  = [lon,lat]\n",
    "radius = None #@param {type:'number'} #(in meters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Export an image from a window given a bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minLng    = None #@param {type:'number'}\n",
    "minLat    = None #@param {type:'number'}\n",
    "maxLng    = None #@param {type:'number'}\n",
    "maxLat    = None #@param {type:'number'}\n",
    "rectangle = [minLng, minLat, maxLng, maxLat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction :\n",
    "#### a) First go to your browser and connect to the Google Drive you used to authenticate to Earth Engine.\n",
    "\n",
    "#### b) Run the following code to construct your image  \n",
    "  \n",
    "*Every time your run a code, if you receive a message like this : \"Please download file from Drive from folder ...\", go to the Google Drive and to the folder mentioned, and download the file in the same folder on your computer.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct inference dataset\n",
    "tfdataconstructor = TFDatasetConstruction(LANDSAT,SENTINEL,RESPONSE,KERNEL_SIZE)\n",
    "corners = tfdataconstructor.test_dataset_construction(start_date,end_date,image_name,point=point,radius=radius,rectangle=rectangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load inference dataset\n",
    "tfdataloader = TFDatasetProcessing(FEATURES_DICT,FEATURES,BANDS,NUM_FEATURES,None)\n",
    "testdataset  = tfdataloader.get_inference_dataset(image_name)\n",
    "NUM_FEATURES = tfdataloader.num_features\n",
    "\n",
    "# Predict and write predictions to .tfrecord (this file will only be useful if you run the III.2.)\n",
    "inference = Inference(NUM_CLASSES,MODEL_NAME)\n",
    "predictions = inference.doMLPrediction(testdataset,image_name,NUM_FEATURES,perform_crf=PERFORM_CRF)\n",
    "\n",
    "# Downloads the label image as KML \n",
    "download_kml(predictions,image_name,*corners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. 2. Pipe Classification, Network Statistics and KMLs\n",
    "Two options, one easy but slow that predicts from scratch each pipe, and another tricky but fast that uses your former predictions :\n",
    "* [1. Easy but slow option](#1.-Easy-but-Slow-Option)\n",
    "* [2. Tricky but fast option](#2.-Tricky-but-Fast-Option)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Easy but Slow Option \n",
    "Using Earth Engine Editor can be tricky for a beginner, so I made the following functions that allow you to assign a class to each pipe and create kml files of colored pipes, without using the editor.\n",
    "These functions are **time consuming** (2 hours for Sieccao for example) but easy to execute.   \n",
    "  \n",
    "*Note* : you should provide a csv of your net (you should have a function in sql_connector.py that does that) with 5 columns :\n",
    "- `Name, lon1, lon2, lat1, lat2`, be careful, the names of the columns should be respected (capital letters included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the name of your csv file :\n",
    "coordsfilename = 'data/predictions/sieccao_classification.csv' #@param \n",
    "\n",
    "# This function assigns a class to each pipe, it takes time to run ! \n",
    "# If you have errors due to multi-processing, set multi_process=False\n",
    "import time\n",
    "s = time.time()\n",
    "predict_pipes_from_csv(coordsfilename,MODEL_NAME, BANDS, \"2020-01-01\",\"2020-12-31\",multi_process=True)\n",
    "e = time.time()\n",
    "print(e-s)\n",
    "\n",
    "# This function calculates the statistics of the network provided (proportion of each class)\n",
    "#get_statistics(coordsfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functions creates a KML of the network provided where each pipe has a color corresponding to its class\n",
    "#If it takes too long, execute the multi-processing version of color_pipe named mp_color_pipes\n",
    "color_pipes(coordsfilename) \n",
    "\n",
    "def mp_color_pipes(file_name) :\n",
    "    import simplekml\n",
    "    import pandas as pd\n",
    "    import matplotlib\n",
    "    import numpy as np\n",
    "    import os\n",
    "    ds_test = pd.read_csv(file_name)\n",
    "    lines = (ds_test['Name'], ds_test['lon1'], ds_test['lat1'], ds_test['lon2'], ds_test['lat2'], ds_test['landcover'])\n",
    "    kml = simplekml.Kml()\n",
    "    ids, lons1, lats1, lons2, lats2, classes = lines\n",
    "    \n",
    "    def color(id, lon1, lat1, lon2, lat2, classe):\n",
    "        line = kml.newlinestring(name=str(id), coords=[(lon1,lat1), (lon2,lat2)])\n",
    "        if classe == 0:\n",
    "            r,g,b = np.multiply(255,matplotlib.colors.to_rgb('lime')).astype(int)\n",
    "        elif classe == 1:\n",
    "            r,g,b = np.multiply(255,matplotlib.colors.to_rgb('darkgreen')).astype(int)\n",
    "        elif classe == 2:\n",
    "            r,g,b = np.multiply(255,matplotlib.colors.to_rgb('yellow')).astype(int)\n",
    "        else:\n",
    "            r,g,b = np.multiply(255,matplotlib.colors.to_rgb('blue')).astype(int)\n",
    "        line.style.linestyle.color = simplekml.Color.rgb(r,g,b)\n",
    "\n",
    "    def color_wrapper(args):\n",
    "        color(*args)\n",
    "        \n",
    "    from multiprocessing.pool import ThreadPool as Pool\n",
    "    p = Pool(5)\n",
    "    \n",
    "    inputs = zip(ids, lons1, lats1, lons2, lats2, classes)\n",
    "    p.map(color_wrapper,inputs)\n",
    "    name = os.path.splitext(os.path.basename(file_name))[0].split('_classification')[0]\n",
    "    kml.save('data/predictions/colored_pipes/'+name+'_colored.kml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordsfilename = 'data/predictions/coords.csv' #@param \n",
    "mp_color_pipes(coordsfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tricky but Fast Option \n",
    "#### Requires you use Earth Engine Editor and you run first the section [III.1.Label Image](III.1.Label-Image)\n",
    "The following functions are VERY fast, but in order to run them, you should add your predictions (calculated in III.1 Label Image) to your Google Earth Editor's Assets by following the tutorial [Add Image to Assets](#2.-Add-Image-to-Assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'saur' #@param can be 'sieccao', 'brioude', 'saur' or the name of your network you just added to Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produce a csv file with pipe names, coordinates and classes\n",
    "predict_pipes(network_name,image_name) #image_name is the name of the image you created in the 2nd section \"creating a label image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formats the csv in order to have the right columns : Name, lon1,lon2,lat1,la2\n",
    "clean_predictions(image_name)\n",
    "filename = 'data/predictions/'+image_name+'_classification.csv'\n",
    "\n",
    "#Calculates statistics of your network (the proportions of each class)\n",
    "get_statistics(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functions creates a KML of the network provided where each pipe has a color corresponding to its class\n",
    "#If it takes too long, execute the multi-processing version of color_pipe named mp_color_pipes\n",
    "color_pipes(filename) \n",
    "\n",
    "def mp_color_pipes(filename) :\n",
    "    import simplekml\n",
    "    import pandas as pd\n",
    "    import matplotlib\n",
    "    import numpy as np\n",
    "    ds_test = pd.read_csv(file_name)\n",
    "    lines = (ds_test['Name'], ds_test['lon1'], ds_test['lat1'], ds_test['lon2'], ds_test['lat2'], ds_test['landcover'])\n",
    "    kml = simplekml.Kml()\n",
    "    ids, lons1, lats1, lons2, lats2, classes = lines\n",
    "    \n",
    "    def color(id, lon1, lat1, lon2, lat2, classe):\n",
    "        line = kml.newlinestring(name=str(id), coords=[(lon1,lat1), (lon2,lat2)])\n",
    "        if classe == 0: #color of fields\n",
    "            r,g,b = np.multiply(255,matplotlib.colors.to_rgb('lime')).astype(int)\n",
    "        elif classe == 1: #color of forests\n",
    "            r,g,b = np.multiply(255,matplotlib.colors.to_rgb('darkgreen')).astype(int)\n",
    "        elif classe == 2: #color of urbain areas\n",
    "            r,g,b = [225,112,112]\n",
    "        else: #color of water\n",
    "            r,g,b = np.multiply(255,matplotlib.colors.to_rgb('blue')).astype(int)\n",
    "        line.style.linestyle.color = simplekml.Color.rgb(r,g,b)\n",
    "\n",
    "    def color_wrapper(args):\n",
    "        color(*args)\n",
    "        \n",
    "    from multiprocessing.pool import ThreadPool as Pool\n",
    "    p = Pool(5)\n",
    "    \n",
    "    inputs = zip(ids, lons1, lats1, lons2, lats2, classes)\n",
    "    p.map(color_wrapper,inputs)\n",
    "    name = os.path.splitext(os.path.basename(filename))[0].split('_classification')[0]\n",
    "    kml.save('data/predictions/colored_pipes/'+name+'_colored.kml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_color_pipes(coordsfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Tutorials\n",
    "The Earth Engine (EE) Code Editor at https://code.earthengine.google.com is a web-based IDE for the Earth Engine JavaScript API. Code Editor features are designed to make developing complex geospatial workflows fast and easy. The Code Editor has the following elements :\n",
    "* JavaScript code editor\n",
    "* Map display for visualizing geospatial datasets\n",
    "* API reference documentation (Docs tab)\n",
    "* Git-based Script Manager (Scripts tab)\n",
    "* Console output (Console tab)\n",
    "* Task Manager (Tasks tab) to handle long-running queries\n",
    "* Interactive map query (Inspector tab)\n",
    "* Search of the data archive or saved scripts\n",
    "* Geometry drawing tools\n",
    "  \n",
    "<img src=\"tuto_images/earth-engine-code-editor.PNG\" width=500>\n",
    "\n",
    "Read https://developers.google.com/earth-engine/guides/playground for more information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Add Table to Assets\n",
    "\n",
    "- **1.** If your file is a \"kml\" file, convert it to a \".shp\" file by using **QGIS software** : \n",
    "  * **a.** Drag your kml to the QGIS window.\n",
    "  * **b.** Right-click on your layer and choose \"Export\" then \"Export Feature As\"  \n",
    "  <img src=\"tuto_images/3.PNG\" width=\"400\">  \n",
    "\n",
    "  * **c.** Set \"Format\" as \"ESRI Shapefile\" and the CRS as \"EPSG:3857 / Pseudo-Mercator\"  \n",
    "  * **d.** Fill \"File name\" to the name of the file. Careful, you should provide the directory : example C:\\....pipe.shp\n",
    "  * **e.** Click on \"OK\" and wait, this could take a moment. Now you have created several files, please keep them all.    \n",
    "  <img src=\"tuto_images/4.PNG\" width=\"400\"> \n",
    "    \n",
    "- **2.** Upload your files to your Google Earth Engine Editor :   \n",
    "  * **a.** Go to https://code.earthengine.google.com/\n",
    "  * **b.** Click on \"Assets\", then \"NEW\", then below \"Table Upload\", click on \"Shape files\".  \n",
    "  <img src=\"tuto_images/5.PNG\" width=\"400\">\n",
    "  * **c.** Select all the files you just created with QGIS.  \n",
    "  * **d.** Name your Table, for example \"saur_zone2\"\n",
    "  * **e.** Click on \"UPLOAD\"  \n",
    "  <img src=\"tuto_images/16.PNG\" width=\"400\">\n",
    "  - **f.** On the right corner of your screen, click on \"Tasks\". Check the status of your export.  \n",
    "  <img src=\"tuto_images/17.PNG\" width=\"400\">\n",
    " \n",
    "Now you can access your table by typing : image = ee.FeatureCollection(assetid) with assetid = directory/network_name.\n",
    "You can find the assetid by clicking on the asset.  \n",
    "<img src=\"tuto_images/11.PNG?modified=02022021134100\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add Image to Assets\n",
    "*replace `filename` by the name of your inference image in the tutorial below*\n",
    "\n",
    "- **1.** First, if not already done, add your network to Google Earth Editor's Assets following the tutorial in the previous section.\n",
    "- **2.** Go to https://code.earthengine.google.com/ .\n",
    "- **3.** Click on \"Assets\", then \"NEW\", then below \"Image Upload\", click on \"GeoTIFF\".  \n",
    "<img src=\"tuto_images/1.PNG\" width=\"400\">\n",
    "- **4.** In \"Sources files\" select the files `pred_filename.TFRecord` and `filename-mixer.json` in your folder 'inference'\n",
    "- **5.** Set \"AssetId\" to \"`filename`_pred\"\n",
    "- **6.** Click on \"UPLOAD\"  \n",
    "<img src=\"tuto_images/2.PNG\" width=\"400\">\n",
    "- **7.** On the right corner of your screen, click on \"Tasks\". Check the status of your export.  \n",
    "If there's an error \"cannot read mixer file\", retry the steps above by putting the mixer file before the tfrecord file and vise-versa several times until you succeed, the system bugs sometimes.  \n",
    "<img src=\"tuto_images/6.PNG\" width=\"400\">\n",
    "\n",
    "Now you can access your image by typing : var image = **ee.Image(assetid)** with assetid=\"directory/filename_pred\"  \n",
    "You can find the assetid by clicking on the asset.  \n",
    "<img src=\"tuto_images/7.PNG?modified=02022021134700\" width=\"400\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}