{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to this inference tutorial\n",
    "            \n",
    "### There are 3 different steps\n",
    ">- 1) Install and import libraries, create folders and define parameters.  \n",
    ">    *Variables followed by **#@param** are variables, you can change them.*\n",
    ">- 2) Creating a mask image of labels.\n",
    ">- 3) Assigning a class to pipes, calculating statistics and creating colored pipes  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Libraries\n",
    "### First create a new **virtual environment** then install all requirements by running the following :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b->-r requirements.txt (line 4)) (7.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from sklearn->-r requirements.txt (line 7)) (0.23.1)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from imblearn->-r requirements.txt (line 8)) (0.7.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 12)) (2020.1)\n",
      "Requirement already satisfied: psutil>=5.6.6 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from swifter->-r requirements.txt (line 13)) (5.7.0)\n",
      "Requirement already satisfied: dask[dataframe]>=2.10.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from swifter->-r requirements.txt (line 13)) (2.20.0)\n",
      "Requirement already satisfied: tqdm>=4.33.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from swifter->-r requirements.txt (line 13)) (4.47.0)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0cloudpickle>=0.2.2 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from swifter->-r requirements.txt (line 13)) (7.5.1)\n",
      "Requirement already satisfied: parso>0.4.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from swifter->-r requirements.txt (line 13)) (0.7.0)\n",
      "Requirement already satisfied: bleach>=3.1.1 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from swifter->-r requirements.txt (line 13)) (3.1.5)\n",
      "Collecting modin[ray]>=0.8.1.1\n",
      "  Using cached modin-0.8.3-py3-none-win_amd64.whl (564 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from google-auth>=1.4.1->earthengine-api->-r requirements.txt (line 1)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from google-auth>=1.4.1->earthengine-api->-r requirements.txt (line 1)) (4.6)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from google-auth>=1.4.1->earthengine-api->-r requirements.txt (line 1)) (49.2.0.post20200714)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from google-auth>=1.4.1->earthengine-api->-r requirements.txt (line 1)) (4.1.1)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from google-api-python-client>=1.12.1->earthengine-api->-r requirements.txt (line 1)) (1.25.1)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from google-api-python-client>=1.12.1->earthengine-api->-r requirements.txt (line 1)) (3.0.1)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from google-cloud-storage->earthengine-api->-r requirements.txt (line 1)) (2.24.0)\n",
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "modin 0.8.3 requires pandas==1.1.5, but you'll have pandas 1.0.5 which is incompatible.\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=1.2.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from google-cloud-storage->earthengine-api->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.1 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from google-cloud-storage->earthengine-api->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from httplib2shim->earthengine-api->-r requirements.txt (line 1)) (1.25.9)\n",
      "Requirement already satisfied: certifi in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from httplib2shim->earthengine-api->-r requirements.txt (line 1)) (2020.6.20)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 2)) (1.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 2)) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 2)) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->-r requirements.txt (line 7)) (2.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter->-r requirements.txt (line 13)) (5.3.1)\n",
      "Requirement already satisfied: fsspec>=0.6.0; extra == \"dataframe\" in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter->-r requirements.txt (line 13)) (0.7.4)\n",
      "Requirement already satisfied: partd>=0.3.10; extra == \"dataframe\" in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter->-r requirements.txt (line 13)) (1.1.0)\n",
      "Requirement already satisfied: toolz>=0.8.2; extra == \"dataframe\" in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from dask[dataframe]>=2.10.0->swifter->-r requirements.txt (line 13)) (0.10.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (5.0.7)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (4.3.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (5.3.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (3.5.1)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (7.16.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from bleach>=3.1.1->swifter->-r requirements.txt (line 13)) (20.4)\n",
      "Requirement already satisfied: webencodings in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from bleach>=3.1.1->swifter->-r requirements.txt (line 13)) (0.5.1)\n",
      "Collecting pyarrow==1.0; extra == \"ray\"\n",
      "  Downloading pyarrow-1.0.0-cp38-cp38-win_amd64.whl (10.5 MB)\n",
      "Collecting ray>=1.0.0; extra == \"ray\"\n",
      "  Downloading ray-1.1.0-cp38-cp38-win_amd64.whl (15.3 MB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->earthengine-api->-r requirements.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.12.1->earthengine-api->-r requirements.txt (line 1)) (1.52.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->earthengine-api->-r requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->earthengine-api->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\" in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage->earthengine-api->-r requirements.txt (line 1)) (1.1.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: locket in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from partd>=0.3.10; extra == \"dataframe\"->dask[dataframe]>=2.10.0->swifter->-r requirements.txt (line 13)) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (3.2.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (4.6.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from traitlets>=4.3.1->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (4.4.2)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (6.0.4)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (6.1.7)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (6.0.3)\n",
      "Requirement already satisfied: pygments in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (2.6.1)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (0.17.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (3.0.5)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (0.7.5)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (0.4.3)\n",
      "Requirement already satisfied: backcall in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (0.2.0)\n",
      "Collecting py-spy>=0.2.0\n",
      "  Using cached py_spy-0.3.4-py2.py3-none-win_amd64.whl (1.4 MB)\n",
      "Collecting aioredis\n",
      "  Using cached aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
      "Collecting opencensus\n",
      "  Using cached opencensus-0.7.12-py2.py3-none-any.whl (127 kB)\n",
      "Collecting gpustat\n",
      "  Using cached gpustat-0.6.0.tar.gz (78 kB)\n",
      "Collecting aiohttp-cors\n",
      "  Using cached aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter->-r requirements.txt (line 13)) (0.8.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter->-r requirements.txt (line 13)) (1.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter->-r requirements.txt (line 13)) (3.0.12)\n",
      "Collecting colorful\n",
      "  Using cached colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
      "Collecting redis>=3.5.0\n",
      "  Using cached redis-3.5.3-py2.py3-none-any.whl (72 kB)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter->-r requirements.txt (line 13)) (7.1.2)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.7.3-cp38-cp38-win_amd64.whl (634 kB)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage->earthengine-api->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->-r requirements.txt (line 2)) (3.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (0.16.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (19.3.0)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (227)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (19.0.1)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (5.6.1)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (0.8.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (2.11.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (0.2.5)\n",
      "Collecting async-timeout\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Collecting hiredis\n",
      "  Downloading hiredis-1.1.0-cp38-cp38-win_amd64.whl (15 kB)\n",
      "Collecting opencensus-context==0.1.2\n",
      "  Using cached opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting nvidia-ml-py3>=7.352.0\n",
      "  Using cached nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "Collecting blessings>=1.6\n",
      "  Using cached blessings-1.7-py3-none-any.whl (18 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp38-cp38-win_amd64.whl (125 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from aiohttp->ray>=1.0.0; extra == \"ray\"->modin[ray]>=0.8.1.1->swifter->-r requirements.txt (line 13)) (3.7.4.2)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.1.0-cp38-cp38-win_amd64.whl (48 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage->earthengine-api->-r requirements.txt (line 1)) (2.20)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (0.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (0.6.0)\n",
      "Requirement already satisfied: testpath in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (0.4.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (1.4.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\leakm\\anaconda3\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0cloudpickle>=0.2.2->swifter->-r requirements.txt (line 13)) (1.1.1)\n",
      "Building wheels for collected packages: swifter, gpustat, nvidia-ml-py3\n",
      "  Building wheel for swifter (setup.py): started\n",
      "  Building wheel for swifter (setup.py): finished with status 'done'\n",
      "  Created wheel for swifter: filename=swifter-1.0.7-py3-none-any.whl size=13983 sha256=a0a52e6ea95440c9f75af2cc6b9a89303e856479487b5d99f74f65acae1dd329\n",
      "  Stored in directory: c:\\users\\leakm\\appdata\\local\\pip\\cache\\wheels\\cc\\a3\\ca\\87533bb1e618d962a03e9286da38e9e21b1d135848f1112bda\n",
      "  Building wheel for gpustat (setup.py): started\n",
      "  Building wheel for gpustat (setup.py): finished with status 'done'\n",
      "  Created wheel for gpustat: filename=gpustat-0.6.0-py3-none-any.whl size=12625 sha256=820851ea7b6d3ad8c8728e8eec8d676f0e34db664e03ac2234ae00c19b5d5510\n",
      "  Stored in directory: c:\\users\\leakm\\appdata\\local\\pip\\cache\\wheels\\0d\\d9\\80\\b6cbcdc9946c7b50ce35441cc9e7d8c5a9d066469ba99bae44\n",
      "  Building wheel for nvidia-ml-py3 (setup.py): started\n",
      "  Building wheel for nvidia-ml-py3 (setup.py): finished with status 'done'\n",
      "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19196 sha256=7252f3b95a7af2c38cec80f70793f2ea54abe43725f416ef657fcb8c2bd3a5ec\n",
      "  Stored in directory: c:\\users\\leakm\\appdata\\local\\pip\\cache\\wheels\\b9\\b1\\68\\cb4feab29709d4155310d29a421389665dcab9eb3b679b527b\n",
      "Successfully built swifter gpustat nvidia-ml-py3\n",
      "Installing collected packages: pyarrow, py-spy, async-timeout, hiredis, aioredis, opencensus-context, opencensus, nvidia-ml-py3, blessings, gpustat, multidict, yarl, aiohttp, aiohttp-cors, colorful, redis, ray, modin, swifter\n",
      "Successfully installed aiohttp-3.7.3 aiohttp-cors-0.7.0 aioredis-1.3.1 async-timeout-3.0.1 blessings-1.7 colorful-0.5.4 gpustat-0.6.0 hiredis-1.1.0 modin-0.8.3 multidict-5.1.0 nvidia-ml-py3-7.352.0 opencensus-0.7.12 opencensus-context-0.1.2 py-spy-0.3.4 pyarrow-1.0.0 ray-1.1.0 redis-3.5.3 swifter-1.0.7 yarl-1.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all folders you will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_folders\n",
    "create_folders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your directory shoud be as following :\n",
    "Check if the folders (the ones **in bold**) are in your directory.\n",
    "- **Main folder**\n",
    "    >- **models**\n",
    "    >    >* .joblib files (sklearn models)\n",
    "    >    >* .sav files (mappers such as pca and umap)\n",
    "    >    >* folders (tensorflow models)\n",
    "    >- **results**\n",
    "    >    >* .png images (confusion matrices)\n",
    "    >    >* .log files (tensorflow training curves)\n",
    "    >- **data**\n",
    "    >    >- **train**\n",
    "    >    >    * train*.tfrecord.gz files (training dataset)\n",
    "    >    >- **eval**\n",
    "    >    >    * traineval*.tfrecord.gz files (evaluation dataset)\n",
    "    >    >- **inference**\n",
    "    >    >   * .tfrecord.gz files (inference dataset)\n",
    "    >    >   * *-mixer.json files (needed for georeferencing, if you want to add the prediction to Earth Engine Editor)\n",
    "    >    >- **predictions**\n",
    "    >    >    - **colored_pipes**\n",
    "    >    >        * .kml files (colored-pipe nets corresponding to labels)\n",
    "    >    >    - **kml**\n",
    "    >    >        * .kml files and corresponding .png images (mask-prediction images)\n",
    "    >    >    - **tfrecords**\n",
    "    >    >        * .TFRecord files (needed if you want to add the prediction to Earth Engine Editor)\n",
    "    >    >    * .csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import, authenticate and initialize the Earth Engine library.  \n",
    "If you have a gmail account, do so with yours, if not, you can use this one :  \n",
    "Gmail adress : [mounierseb93@gmail.com]    \n",
    "Code : [mounse$15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=nuXWWIgpJuhoXcHMSExZzXcshKuG1uajK0l9jvuXoAw&code_challenge_method=S256>https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=nuXWWIgpJuhoXcHMSExZzXcshKuG1uajK0l9jvuXoAw&code_challenge_method=S256</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you\n",
       "        should paste in the box below</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from dataset_construction import TFDatasetConstruction\n",
    "from dataset_loader import TFDatasetProcessing, NPDatasetProcessing, undersample\n",
    "from models import ModelTrainingAndEvaluation\n",
    "from inference import Inference, download_kml\n",
    "from utils import predict_pipes, predict_pipes_from_csv, clean_predictions, color_pipes, get_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify inputs of your project\n",
    "MODEL_NAME = 'rf' #@param #the name of the model (without the extension), it should be the same as the one in your folder \"models\"\n",
    "\n",
    "LANDSAT  = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B10', 'B11']\n",
    "SENTINEL = ['VV','VH','VV_1','VH_1']\n",
    "BANDS    = LANDSAT + SENTINEL\n",
    "RESPONSE = 'landcover'\n",
    "FEATURES = BANDS+[RESPONSE]\n",
    "KERNEL_SIZE   = 128\n",
    "KERNEL_SHAPE  = [KERNEL_SIZE, KERNEL_SIZE]\n",
    "COLUMNS       = [tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES]\n",
    "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
    "NUM_FEATURES  = len(BANDS)\n",
    "NUM_CLASSES   = 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Creating a label image\n",
    "### a) First connect to Google Drive. If you have a gmail account, do so with yours, if not, you can use this one :  \n",
    "Gmail adress : [mounierseb93@gmail.com]    \n",
    "Code : [mounse$15]\n",
    "\n",
    "**Every time your run a code, if you receive a message like this : \"Please download file from Drive from folder ...\", go to the Google Drive and to the folder mentioned, and download the file in the same folder on your computer.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) You have three options to how you create your test image :**\n",
    ">**1)** Export an image from a square window of a given center [[Lon,Lat]] and [radius] (in meters)   \n",
    ">**2)** Export an image from a window given a bounding box [[Lon1, Lat1, Lon2, Lat2]]  \n",
    ">**3)** Export the whole area of a network* (for the brave who want to use Earth Engine's Editor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*CAREFUL* ! if you want to **export the whole area of a network** (the 3d option) : \n",
    "\n",
    "If your network is not already uploaded to your **Google Earth Editor Assets** (I have already added sieccao, saur (zone 1) and brioude), either provide a bounding box covering the whole area of the network (follow the second option) OR follow these steps :\n",
    ">\n",
    ">- If your file is not a **shp** file, for example a **kml**, convert it to \".shp\" using QGIS :\n",
    ">    * Drag your kml to the QGIS window.\n",
    ">    * Right-click on your layer and choose \"Export\" then \"Export Feature As\"\n",
    ">    * Set \"Format\" as \"ESRI Shapefile\" and the \"CRS\" as \"EPSG:3857 / Pseudo-Mercator\"\n",
    ">    * Fill \"File name\" to the name of the file. Careful, you should provide the directory : example \"C:\\....pipe.shp\"\n",
    ">    * Click on \"OK\" and wait, this could take a moment. Now you have created several files, please keep them all.\n",
    ">- Upload your files to your Google Earth Engine Editor :\n",
    ">    * Go to https://code.earthengine.google.com/\n",
    ">    * Click on \"Assets\", then \"NEW\", then below \"Table Upload\", click on \"Shape files\". Select all the files you just >created with QGIS.\n",
    ">    * Set Assetid to the name of your network ie \"brioude\"\n",
    ">    * Click on \"UPLOAD\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify inference parameters\n",
    "start_date = \"2020-01-01\"\n",
    "end_date   = \"2020-12-31\"\n",
    "image_name = 'test' #Name your image as you want'\n",
    "\n",
    "#FILL ONLY ONE OF THE FOLLOWING :\n",
    "\n",
    "# 1) if you want to export an image from a square window of a given center and radius (meters) :\n",
    "lon    = None #@param {type;'number'}\n",
    "lat    = None #@param {type:'number'}\n",
    "point  = [lon,lat]\n",
    "radius = None #@param {type:'number'} (in meters)\n",
    "\n",
    "# 2) if you want to export an image from a window given a bounding box\n",
    "minLng    = None #@param {type:'number'}\n",
    "minLat    = None #@param {type:'number'}\n",
    "maxLng    = None #@param {type:'number'}\n",
    "maxLat    = None #@param {type:'number'}\n",
    "rectangle = [minLng, minLat, maxLng, maxLat]\n",
    "\n",
    "# 3) if you want to export the whole area of a network\n",
    "# can be 'brioude','sieccao','saur' or the name of your network you just created following the tutorial above\n",
    "network_name = None #@param {type:'string'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running export...\n",
      "Image and Mixer export completed\n",
      "Please download all files starting with \"test\" from drive (directory data/inference) if you work on your local computer\n"
     ]
    }
   ],
   "source": [
    "# Construct inference dataset\n",
    "tfdataconstructor = TFDatasetConstruction(LANDSAT,SENTINEL,RESPONSE,KERNEL_SIZE)\n",
    "corners = tfdataconstructor.test_dataset_construction(start_date,end_date,image_name,network_name=network_name,point=point,radius=radius,rectangle=rectangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whether to perform Conditional Random Fields on your predictions\n",
    "PERFORM_CRF = False #@param\n",
    "\n",
    "if PERFORM_CRF == True :\n",
    "    !pip install --upgrade cython\n",
    "    !pip install --upgrade pydensecrf\n",
    "    \n",
    "#If you are on windows and have trouble installing pydensecrf : \n",
    "#if you use anaconda, execute the following : conda install -c conda-forge pydensecrf').\n",
    "#if not, or you have more fails, check https://github.com/lucasb-eyer/pydensecrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for TFRecord files...\n",
      "files found :  ['data\\\\inference\\\\test-00000.tfrecord.gz', 'data\\\\inference\\\\test-mixer.json']\n",
      "Running predictions...\n",
      "Writing predictions...\n",
      "Kml saved at \"data/predictions/kml\"\n"
     ]
    }
   ],
   "source": [
    "# Load and predict inference dataset and write predictions\n",
    "tfdataloader = TFDatasetProcessing(FEATURES_DICT,FEATURES,BANDS,NUM_FEATURES,None)\n",
    "testdataset  = tfdataloader.get_inference_dataset(image_name)\n",
    "NUM_FEATURES = tfdataloader.num_features\n",
    "\n",
    "inference = Inference(NUM_CLASSES,MODEL_NAME)\n",
    "predictions = inference.doMLPrediction(testdataset,image_name,NUM_FEATURES,perform_crf=PERFORM_CRF)\n",
    "\n",
    "# This function downloads the label image as KML \n",
    "download_kml(predictions,image_name,*corners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Assigning a class to pipes, calculating statistics and creating colored pipes\n",
    "Two options, one easy but slow that predicts from scratch each pipe, and another tricky but fast that uses your former predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Easy but slow option (no need to run the 2nd section \"Creating a label image\")\n",
    "Using Earth Engine Editor can be tricky for a beginner, so I made the following functions that allow you to assign a class to each pipe and create kml files of colored pipes, without using the editor.\n",
    "These functions are **time consuming** (4 hours for Sieccao for example) but easy to execute.   \n",
    "*Note* : you should provide a csv of your net (you should have a function in sql_connector.py that does that) with 5 columns as : \n",
    "- [Name] for the pipe id\n",
    "- [lon1, lon2, lat1, lat2] for the coordinates of each pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the name of your csv file :\n",
    "coordsfilename = 'data/predictions/coords.csv' #@param \n",
    "\n",
    "# This function assigns a class to each pipe, it takes time to run ! \n",
    "predict_pipes_from_csv(coordsfilename,MODEL_NAME, BANDS, \"2020-01-01\",\"2020-12-31\")\n",
    "\n",
    "# This function calculates the statistics of the network provided (proportion of each class)\n",
    "get_statistics(coordsfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functions creates a KML of the network provided where each pipe has a color corresponding to its class\n",
    "#If it takes too long, execute the multi-processing version of color_pipe named mp_color_pipes\n",
    "color_pipes(coordsfilename) \n",
    "\n",
    "def mp_color_pipes(filename) :\n",
    "    import simplekml\n",
    "    import pandas as pd\n",
    "    import matplotlib\n",
    "    import numpy as np\n",
    "    ds_test = pd.read_csv(file_name)\n",
    "    lines = (ds_test['Name'], ds_test['lon1'], ds_test['lat1'], ds_test['lon2'], ds_test['lat2'], ds_test['landcover'])\n",
    "    kml = simplekml.Kml()\n",
    "    ids, lons1, lats1, lons2, lats2, classes = lines\n",
    "    \n",
    "    def color(id, lon1, lat1, lon2, lat2, classe):\n",
    "        line = kml.newlinestring(name=str(id), coords=[(lon1,lat1), (lon2,lat2)])\n",
    "        if classe == 0:\n",
    "            r,g,b = np.multiply(255,matplotlib.colors.to_rgb('lime')).astype(int)\n",
    "        elif classe == 1:\n",
    "            r,g,b = np.multiply(255,matplotlib.colors.to_rgb('darkgreen')).astype(int)\n",
    "        elif classe == 2:\n",
    "            r,g,b = np.multiply(255,matplotlib.colors.to_rgb('yellow')).astype(int)\n",
    "        else:\n",
    "            r,g,b = np.multiply(255,matplotlib.colors.to_rgb('blue')).astype(int)\n",
    "        line.style.linestyle.color = simplekml.Color.rgb(r,g,b)\n",
    "\n",
    "    def color_wrapper(args):\n",
    "        color(*args)\n",
    "        \n",
    "    from multiprocessing.pool import ThreadPool as Pool\n",
    "    p = Pool(5)\n",
    "    \n",
    "    inputs = zip(ids, lons1, lats1, lons2, lats2, classes)\n",
    "    p.map(color_wrapper,inputs)\n",
    "    name = os.path.splitext(os.path.basename(filename))[0].split('_classification')[0]\n",
    "    kml.save('data/predictions/colored_pipes/'+name+'_colored.kml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_color_pipes(coordsfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Tricky but fast option (use Earth Engine's Editor)\n",
    "The following functions are VERY fast, but in order to run them, you should add your predictions (calculated in the 2nd section \"Creating a label image\") to your Google Earth Editor's Assets, the two files listed below have been created throughout inference.  \n",
    "*(replace filename by the name of your inference image in the tutorial below)*\n",
    "\n",
    "- First, if not already done, add your network to Google Earth Editor's Assets following the tutorial in the previous section.\n",
    "- Go to https://code.earthengine.google.com/ .\n",
    "- Click on \"Assets\", then \"NEW\", then below \"Image Upload\", click on \"GeoTIFF\".\n",
    "- In \"Sources files\" select the **filename.TFRecord** file in your folder 'tfrecords' under 'predictions' (ie select predictions/tfrecords/filename.TFRecord)\n",
    "- Add to \"Sources files\" the **filename-mixer.json** file in your folder 'inference' (ie select inference/filename-mixer.json)\n",
    "- Set \"AssetId\" to \"filename_pred\"\n",
    "- Click on \"UPLOAD\"\n",
    "- On the right corner of your screen, click on \"Tasks\". Check the status of your export.\n",
    "- If there's an error \"cannot read mixer file\", retry the steps above by putting the mixer file before the tfrecord file and vise-versa several times until you succeed, the system bugs sometimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = 'saur' #@param can be 'sieccao', 'brioude', 'saur' or the name of your network you just added to Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produce a csv file with pipe names, coordinates and classes\n",
    "predict_pipes(network_name,image_name) #image_name is the name of the image you created in the 2nd section \"creating a label image\"\n",
    "\n",
    "#Formats the csv in order to have the right columns : Name, lon1,lon2,lat1,la2\n",
    "clean_predictions(image_name)\n",
    "filename = 'data/predictions/'+image_name+'_classification.csv'\n",
    "\n",
    "#Calculates statistics of your network (the proportions of each class)\n",
    "get_statistics(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This functions creates a KML of the network provided where each pipe has a color corresponding to its class\n",
    "#If it takes too long, execute the multi-processing version of color_pipe named mp_color_pipes\n",
    "color_pipes(filename) \n",
    "\n",
    "def mp_color_pipes(filename) :\n",
    "    import simplekml\n",
    "    import pandas as pd\n",
    "    import matplotlib\n",
    "    import numpy as np\n",
    "    ds_test = pd.read_csv(file_name)\n",
    "    lines = (ds_test['Name'], ds_test['lon1'], ds_test['lat1'], ds_test['lon2'], ds_test['lat2'], ds_test['landcover'])\n",
    "    kml = simplekml.Kml()\n",
    "    ids, lons1, lats1, lons2, lats2, classes = lines\n",
    "    \n",
    "    def color(id, lon1, lat1, lon2, lat2, classe):\n",
    "        line = kml.newlinestring(name=str(id), coords=[(lon1,lat1), (lon2,lat2)])\n",
    "        if classe == 0:\n",
    "            r,g,b = np.multiply(255,matplotlib.colors.to_rgb('lime')).astype(int)\n",
    "        elif classe == 1:\n",
    "            r,g,b = np.multiply(255,matplotlib.colors.to_rgb('darkgreen')).astype(int)\n",
    "        elif classe == 2:\n",
    "            r,g,b = np.multiply(255,matplotlib.colors.to_rgb('yellow')).astype(int)\n",
    "        else:\n",
    "            r,g,b = np.multiply(255,matplotlib.colors.to_rgb('blue')).astype(int)\n",
    "        line.style.linestyle.color = simplekml.Color.rgb(r,g,b)\n",
    "\n",
    "    def color_wrapper(args):\n",
    "        color(*args)\n",
    "        \n",
    "    from multiprocessing.pool import ThreadPool as Pool\n",
    "    p = Pool(5)\n",
    "    \n",
    "    inputs = zip(ids, lons1, lats1, lons2, lats2, classes)\n",
    "    p.map(color_wrapper,inputs)\n",
    "    name = os.path.splitext(os.path.basename(filename))[0].split('_classification')[0]\n",
    "    kml.save('data/predictions/colored_pipes/'+name+'_colored.kml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_color_pipes(coordsfilename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
